{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import boto3\n",
    "from io import BytesIO\n",
    "import sagemaker.amazon.common as smac\n",
    "from sagemaker import get_execution_role\n",
    "import glob2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "-----------------------------------------------------------------------------\n",
    "--- Inputs\n",
    "-----------------------------------------------------------------------------\n",
    "'''\n",
    "dataColumn = 'L6'\n",
    "coor = 'Char'\n",
    "\n",
    "resultsList = ['Indicies','Response']\n",
    "#interpolationList = ['NoInterp','Interp']\n",
    "analysisList = ['AE_Simple','DEC_Simple','PCA']\n",
    "interpolationList = ['NoInterp']\n",
    "#analysisList = ['KMA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "-----------------------------------------------------------------------------\n",
    "--- Definitions\n",
    "-----------------------------------------------------------------------------\n",
    "'''\n",
    "\n",
    "# Configuring S3\n",
    "s3_bucket_name = 'jasper-ml-sagemaker'\n",
    "role = get_execution_role()\n",
    "\n",
    "client = boto3.client('s3')\n",
    "resource = boto3.resource('s3')\n",
    "my_bucket = resource.Bucket(s3_bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "-----------------------------------------------------------------------------\n",
    "--- Transfer Results\n",
    "-----------------------------------------------------------------------------\n",
    "'''\n",
    "\n",
    "for interpolation in interpolationList:\n",
    "    for analysis in analysisList:\n",
    "        \n",
    "        resultsPath = '{}/{}/{}/'.format(results, interpolation,analysis)\n",
    "\n",
    "        files = []\n",
    "        for object_summary in my_bucket.objects.filter(Prefix=resultsPath):\n",
    "            files.append(object_summary.key[len(resultsPath):])\n",
    "            \n",
    "        dimensionList = []\n",
    "        for file in files:\n",
    "            if file != '.DS_Store':\n",
    "                dimensionList.append(file.split('/')[0])\n",
    "        \n",
    "        dimensionList = list(set(dimensionList))\n",
    "        \n",
    "        for dimension in dimensionList:\n",
    "            resultsPath = '{}/{}/{}/{}/'.format(results, interpolation,analysis,dimension)\n",
    "            newResultsPath = '{}/{}/{}/{}/{}/{}/'.format(dataColumn,coor,interpolation,analysis,dimension,results)            \n",
    "            \n",
    "            files = []\n",
    "            for object_summary in my_bucket.objects.filter(Prefix=resultsPath):\n",
    "                if object_summary.key[len(resultsPath):] != '.DS_Store':\n",
    "                    files.append(object_summary.key[len(resultsPath):])\n",
    "                    \n",
    "            for dataKey in files:\n",
    "                obj = client.get_object(Bucket=s3_bucket_name, Key=resultsPath + dataKey)\n",
    "                pd.read_csv(obj['Body'],header = None).to_csv(dataKey, index=False)\n",
    "                my_bucket.upload_file(dataKey,Key=newResultsPath + dataKey)\n",
    "                os.remove(dataKey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "-----------------------------------------------------------------------------\n",
    "--- Transfer Indicies and Responses\n",
    "-----------------------------------------------------------------------------\n",
    "'''\n",
    "for results in resultsList:\n",
    "    for interpolation in interpolationList:\n",
    "        for analysis in analysisList:\n",
    "\n",
    "            resultsPath = '{}/{}/{}/'.format(results, interpolation, analysis)\n",
    "            newResultsPath = '{}/{}/{}/{}/{}/'.format(dataColumn,coor,interpolation,analysis,results)            \n",
    "\n",
    "            files = []\n",
    "            for object_summary in my_bucket.objects.filter(Prefix=resultsPath):\n",
    "                if object_summary.key[len(resultsPath):] != '.DS_Store':\n",
    "                    files.append(object_summary.key[len(resultsPath):])\n",
    "            \n",
    "            for dataKey in files:\n",
    "                \n",
    "                obj = client.get_object(Bucket=s3_bucket_name, Key=resultsPath + dataKey)\n",
    "                np.save(dataKey,np.load(BytesIO(obj['Body'].read())))\n",
    "                my_bucket.upload_file(dataKey,Key=newResultsPath + dataKey)\n",
    "                os.remove(dataKey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
